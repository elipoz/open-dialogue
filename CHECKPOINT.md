# Checkpoint

**Date:** 2026-02-16

## Summary

Open Dialogue with AI — Streamlit app for N-way dialogue between multiple Moderators, and two AI agents (separate model sessions per agent: OpenAI or Gemini via **AGENT1_USE_MODEL** / **AGENT2_USE_MODEL**, fallback **USE_MODEL**). Conversations and messages are persisted in Supabase; each conversation has a UUID in the URL.

**Recent:** **Delete confirmation:** Delete-conversation dialog now includes an expandable **Conversation history** (collapsed by default) that loads and shows the conversation’s messages in reverse chronological order (newest first); messages loaded via `load_messages(cid)` so the preview is correct even when deleting a different conversation than the current one. **Incremental dialogue load:** 2s fragment fetches only new messages since last known timestamp (`load_messages_since(conv_id, after_created_at)`) when the same conversation is already loaded; full load on first load or when switching conversation. **Supabase cleanup:** `create_conversation()` no longer passes `created_at` (DB sets it via default now()); `persist_message(conv_id, author, message)` no longer takes `created_at`; timestamp parsing extracted to `_sanitize_timestamp()` in supabase_client. **Per-agent model:** Each agent uses its own backend: **AGENT1_USE_MODEL** and **AGENT2_USE_MODEL** (values `openai` or `gemini`); if unset, **USE_MODEL** is used. Status caption shows both, e.g. "Agent 1: OpenAI / gpt-5-mini · Agent 2: Gemini / gemini-2.0-flash". **Reduce agent parroting/echo:** (1) **Differentiated default roles** — Gosha (agent1) focuses on open dialogue as practice (how it’s done, goals in the room, uncertainty); Joshi (agent2) on cultural/postcolonial perspectives (voices, power, silence, worldviews). (2) **Gemini temperature** — default 0.7 (override via `GEMINI_TEMPERATURE` in .env) so replies vary; set in all `GenerateContentConfig` usages. (3) **Reflection anti-parroting** — reflection-phase prompt now explicitly forbids paraphrasing or repeating the other agent; instructs offering a distinct perspective and responding to the other’s reflection with a different take. **Gemini tool-calling (Tavily web_search):** Fixed 400 INVALID_ARGUMENT "Function call is missing a thought_signature" by adding the required thought_signature to every model `function_call` part. In **model.py**: (1) when converting OpenAI messages to Gemini contents, assistant tool_calls are now built as `Part(function_call=..., thought_signature=dummy)` using dummy `b"skip_thought_signature_validator"`; (2) in `call_gemini_for_agent`, every function_call part (from API response or from fallback) is sent with a thought_signature so both the first request and replayed turns validate. Agent reply streams only inside the **Conversation history** panel (as a chat message in the same list as previous messages). Streaming uses plain text in the placeholder to avoid brief font/size jumps from partial markdown; the final message in history still renders with full markdown. **Agent-to-agent:** Agents can trigger each other by @mention or by naming the other (e.g. "Joshi, what do you think?"); with probability P (0–0.5, editable in sidebar) the other agent may also be triggered after a reply; cap N (0–10) limits consecutive agent messages. Sidebar has editable **Agent chain cap (N)** and **Agent reply probability (P)** above Participants; P=0 disables random chain (only @mention/name triggers); N=0 or N=1 means no chain. When the human says e.g. "@j can ask Gosha to respond?", Gosha is triggered after Joshi replies (trigger_after_mention_chain).

**Live app:** https://open-dialogue-with-ai.streamlit.app/
**Supabase:** https://supabase.com/dashboard/project/ijpdpteksbsmchdnerdm/editor/17532?schema=public

## Features

- **Login gate:** Single combined screen: **"To start a dialogue - state your name"**; name field (max 15 chars), then password when required (Streamlit Cloud with `APP_USER_PASSWORD` or `APP_ADMIN_PASSWORD` set), then **Submit**. **Admin:** log in with name **Admin** and `APP_ADMIN_PASSWORD`; only that user can delete conversations (× disabled for others; tooltip "Only Admin can delete conversations"). Other users use `APP_USER_PASSWORD`. Page title becomes **"&lt;name&gt;'s Open Dialogue with AI"** once set. Conversation history and export use the **original author name** for each message (from DB when loaded); new messages use current user name.
- **Send as:** Moderator (default) or Instructor. Single chat input; press Enter to send. Role keys use constants `ROLE_MODERATOR` / `ROLE_INSTRUCTOR` in code.
- **Two agents:** Configurable names and roles in `app.py` (e.g. Gosha, Joshi). Agent name is fixed; only role text is editable. Collapsible role expander and **Respond** button per agent. OpenAI prompts enforce fixed identity: each agent must speak only for themselves, never as Instructor/Moderator/other agent.
- **Agent intro:** Each agent states name and role on first reply and again after its role is updated.
- **Thinking spinner:** One place for both flows — **Respond** or @mention; "agent thinking…" appears in the same full-width row below the agent rows. Agent reply text streams only in the right column inside **Conversation history** (as a chat bubble in the message list), not under the spinner.
- **Streaming:** Reply is streamed into a placeholder inside the conversation history list (same `st.chat_message` style). Placeholder uses plain text during stream to avoid font/size glitches from partial markdown; saved message in history is rendered with markdown.
- **@mentions:** When **Moderator** posts a message that @-mentions an agent, that agent is triggered (every time; no suppression). **Respond** button also triggers. Instructor messages never trigger agents; we clear agent thinking on every new message, then set from @mention only when role is Moderator. Mention pattern: `@` (optional space) then first letter or any prefix of name (e.g. `@g`, `@ gosha`). Stored text is expanded to full agent names in history and for OpenAI. If the human also names the other agent (e.g. "@j can ask Gosha to respond?"), that agent is triggered after the @mentioned agent replies (`trigger_after_mention_chain`).
- **Agent-to-agent:** After an agent replies, the other agent can be triggered by @mention or by naming them in the reply (e.g. "Joshi, what do you think?"); with probability P (sidebar, 0–0.5) they may also be triggered at random. Consecutive agent messages are capped at N (sidebar, 0–10); N=0 or N=1 means no chain. P=0 disables probability (only @mention/name triggers). Session state: `agent_chain_count` (reset on human message or Respond), `agent_cross_mention_n` / `agent_cross_mention_p` (from sidebar inputs).
- **Layout:** Sidebar with conversations list, divider, **Agent chain cap (N)**, **Agent reply probability (P)** (0–0.5), **Reflection duration (min)** (1–10, default 5), **Participants** expander, **Request / response log**. Main: 50% left (controls + spinner), 50% right (conversation history). Under chat input: **Reflect together** and **Stop reflecting** buttons. Above "Conversation history" subheader: **Reverse order** and **Export to doc** when there is dialogue.
- **Conversation history:** Right panel, newest first by default; **Reverse order** toggles; timestamps; each message shows the original poster’s name (DB author or current user for new messages). **Export to doc** downloads full conversation as .docx (via `doc_export.py`). Dialogue loaded from DB before title so Participants list is correct on join.
- **Supabase:** `SUPABASE_URL` and `SUPABASE_KEY` (or anon JWT) in `.env`. New conversation is created **only** when the user clicks **New conversation** (no auto-creation on load). `create_conversation()` inserts with id only; DB sets `created_at` via default now(). `persist_message(conv_id, author_display_name, message)` — no created_at; DB sets message timestamp. On start, if the URL has no valid `conversation_id` and nothing is selected, the app auto-selects the most recent conversation; when the URL has `?conversation_id=<uuid>`, that conversation is always used (URL wins). `od_conversations` has id + created_at. `od_messages` stores author display name in `role`. `load_messages` and `load_messages_since(conv_id, after_created_at)` for incremental reload; `_sanitize_timestamp()` normalizes DB timestamps to UTC. Sidebar lists previous conversations (by created_at); current conversation highlighted in red; each row has **×** to delete. Delete confirmation dialog shows "Delete this conversation? This cannot be undone." with an expandable **Conversation history** (collapsed by default), newest-first, loaded from DB for the conversation being deleted. Tables: run `supabase_migration.sql` in Supabase SQL Editor (includes DROP then CREATE).
- **Multi-user sync:** Multiple users share the same conversation. **2s fragment** (right column) polls and reloads dialogue from DB; when the same conversation is already loaded it uses **incremental** load (`load_messages_since` with last message timestamp) instead of full load. **10s fragment** (sidebar) refreshes the conversation list. Conversation/query state preserved when URL param is missing (no accidental reset); sidebar only clears current when list is non-empty and current id missing. After every `persist_message` (human message, agent reply, role update) we call `_reload_dialogue_from_db()` so the UI always shows the canonical DB state. New conversation is prepended to the list when created. `conversation_exists()`; opening or polling a deleted conversation clears state and reloads. **Dedupe** by conversation id; if current conversation is missing from the list (deleted by another user), selection is cleared. Session-state reset in `_clear_conversation_state()`. Agent intro flags (`agent1_needs_intro`, `agent2_needs_intro`) are synced from dialogue when loading from DB (`_sync_agent_intro_state_from_dialogue()`) so agents don’t re-introduce if they already have messages in the conversation.
- **Timestamps in PST:** All UI timestamps in **America/Los_Angeles (PST)**. `_format_in_pst()` handles both datetime and ISO strings from Supabase; new conversation label uses `_now_pst()`.
- **OpenAI context:** Conversation sent to OpenAI as **one [user] message**: full transcript with **"At &lt;timestamp&gt; &lt;role&gt; said: &lt;message&gt;"** (chronological, including this agent's past replies) then **[Reply now only as &lt;name&gt;.]**. No per-turn user/assistant; who said what is clear from the transcript. Timestamp is message `created_at` from DB; role uses actual names. Agent system prompt instructs: reply with message content only—do not echo "At … said:" or your name as a label.
- **Agent replies:** If the model echoes "At &lt;timestamp&gt; &lt;name&gt; said:" we strip it (`_strip_at_timestamp_said_prefix`); leading "Name: " is also stripped (`_strip_agent_name_prefix`) so the UI label is not duplicated.
- **Refactoring:** Model and Tavily logic live in **model.py** (no app import). Agent thinking in `_run_agent_thinking_if_set`; role row in `_render_agent_role_row`. App calls `call_model_for_agent(..., build_messages_for_agent=_build_messages_for_model)`; model dispatches to OpenAI or Gemini and uses Tavily internally. **model.py:** `get_tavily_client`, `get_tavily_error`, `get_tavily_status()` (caption string), `call_model_for_agent`, `SEARCH_TOOL`; OpenAI/Gemini helpers and `_run_tavily_search` internal.
- **Password (Streamlit Cloud):** When `APP_USER_PASSWORD` or `APP_ADMIN_PASSWORD` is set and running on Streamlit Cloud, the login screen includes name + password + Submit (password omitted when running locally). Admin logs in with name "Admin" and `APP_ADMIN_PASSWORD`; others use `APP_USER_PASSWORD`.
- **Tavily:** Optional `TAVILY_API_KEY` in `.env`; client and search in **model.py**. Status caption under title via `get_tavily_status()` (enabled / disabled / error); shown only after moderator name is set.
- **Model:** Per-agent backend: **AGENT1_USE_MODEL** and **AGENT2_USE_MODEL** (.env), values `openai` or `gemini`; fallback **USE_MODEL** if unset. OpenAI: **OPENAI_MODEL** (default gpt-5-mini). Gemini: **GEMINI_API_KEY** required, **GEMINI_MODEL** (default gemini-2.0-flash). Status caption shows both agents, e.g. "Agent 1: OpenAI / … · Agent 2: Gemini / …". **Temperature:** OpenAI — we only pass temperature when the model is **gpt-4o-mini**; then **OPENAI_TEMPERATURE** from env if set, else API default. Other OpenAI models: no temperature passed. Gemini — **GEMINI_TEMPERATURE** from env; default **1.0**; clamped 0–2. Gemini tool calls require thought_signature on every function_call part (dummy `skip_thought_signature_validator` in `_openai_messages_to_gemini_contents` and `call_gemini_for_agent`). Optional imports (try/except); missing package raises clear error when that backend is selected. Agent prompt instructs taking a different perspective from the other agent when relevant.
- **Request / response log:** In sidebar below Participants; latest request and response after each Respond or @mention. Two collapsible subsections (Request, Response) inside the main expander. Truncation is only for this log (not for the API): in `_log_openai_request`, each message and the response are middle-truncated to 2000 chars via `_truncate_middle` once; the UI displays that stored content as-is. Widget keys include log ts+agent so content refreshes when a new agent reply is logged. Log written in `_run_agent_thinking_if_set` after `call_model_for_agent` returns.
- **Timestamps in DB:** Conversation and message `created_at` are set by Postgres `DEFAULT now()` (app does not pass them). Loaded timestamps normalized to UTC via `_sanitize_timestamp()` in supabase_client. UI shows PST via `_format_in_pst()` at display time only. While an agent is thinking, the streaming placeholder shows caption **"Now"**.
- **Reflect together:** Button under the user message input (with **Stop reflecting** to its right). Duration configurable in sidebar (1–10 min, default 5). Agents take turns reflecting on what was said; deadline enforced (no agent starts after the end time; run cancelled if past). Reflection-phase prompt instructs agents not to paraphrase or repeat the other; to offer a distinct perspective and respond to the other’s reflection with a different take. **Stop reflecting** clears reflection and both agents' thinking flags. Chat input disabled while any agent is thinking.

## Files

- `app.py` — main Streamlit app (imports call_model_for_agent, get_tavily_client, get_tavily_status from model)
- `model.py` — OpenAI/Gemini calls and Tavily (get_tavily_client, get_tavily_error, get_tavily_status, call_model_for_agent, SEARCH_TOOL)
- `supabase_client.py` — Supabase client and helpers (conversation_exists, create_conversation, delete_conversation, list_conversations, load_messages, load_messages_since, persist_message; _sanitize_timestamp, _parse_message_row)
- `doc_export.py` — export dialogue to Word (.docx)
- `supabase_migration.sql` — DROP + CREATE for `od_conversations` and `od_messages` (run in Supabase SQL Editor)
- `pyproject.toml` — dependencies (google-genai, openai, streamlit, python-dotenv, python-docx, supabase, tavily-python)
- `README.md` — setup and usage
- `SUPABASE_PLAN.md` — Supabase integration plan and schema notes
